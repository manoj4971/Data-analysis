{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import heartbeat as hb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import os\n",
    "import glob\n",
    "TrainX=np.empty((0,12))\n",
    "TrainY=np.empty((0))\n",
    "Class={'Mild','Medium','High'}\n",
    "\n",
    "fs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2e2b245d7261>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2e2b245d7261>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    t_x=np.concatenate((t_x,data[i*:i*fs+fs].reshape((1,1000))))\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "t_x=np.empty((0,1000))\n",
    "t_y=np.array([])\n",
    "paths=['D:/highstress','D:/mediumstress','D:/mildstress']\n",
    "labels=['High','Medium','Mild']\n",
    "for label,path_x in enumerate(paths):\n",
    "    print(label)\n",
    "    print(path_x)\n",
    "    ### here add all data files in to one list by using \"os.walk\" function from os library and append data in to s\n",
    "   \n",
    "    s = []\n",
    "    for root, dirs, files in os.walk(path_x):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                #print(os.path.join(root, file))\n",
    "                s.append(os.path.join(root, file))\n",
    "            #print(s)\n",
    "    print(len(s))\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    for f in s:\n",
    "        #data = pd.read_excel(\"D:/highstress/akhil index finger high stress.xlsx\")\n",
    "        data=pd.read_excel(f)\n",
    "        #data=hb.get_data('newppg.csv')\n",
    "        #\"C:/Users/User/Desktop/mediumstress/anne index finger medium stress.xlsx\"\n",
    "        #all_data = all_data.append(df,ignore_index=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###here \"data--datafile\" is a DataFrame cannot be accessed through slicing,we should use iloc or .values functions \n",
    "\n",
    "        data=np.array([data.iloc[:,0].values])\n",
    "        print(data.shape)\n",
    "\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            \n",
    "           \n",
    "            t_x=np.concatenate((t_x,data[i*:i*fs+fs].reshape((1,1000))))\n",
    "\n",
    "            t_y=np.concatenate((t_y,[labels[label]]))\n",
    "\n",
    "    \n",
    "    print(t_x.shape)\n",
    "\n",
    "       \n",
    "   \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-980fba592672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'D:/testhighstress'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'D:/testmediumstress'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'D:/testmildstress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "test_x=np.empty((0,1000))\n",
    "test_y=np.array([])\n",
    "paths=['D:/testhighstress','D:/testmediumstress','D:/testmildstress']\n",
    "labels=['High','Medium','Mild']\n",
    "for label,path_x in enumerate(paths):\n",
    "    print(label)\n",
    "    print(path_x)\n",
    "    ### here add all data files in to one list by using \"os.walk\" function from os library and append data in to s\n",
    "   \n",
    "    s = []\n",
    "    for root, dirs, files in os.walk(path_x):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                #print(os.path.join(root, file))\n",
    "                s.append(os.path.join(root, file))\n",
    "            #print(s)\n",
    "    print(len(s))\n",
    "    \n",
    "    #### h\n",
    "    \n",
    "\n",
    "\n",
    "    for f in s:\n",
    "        #data = pd.read_excel(\"D:/highstress/akhil index finger high stress.xlsx\")\n",
    "        data=pd.read_excel(f)\n",
    "        #data=hb.get_data('newppg.csv')\n",
    "        #\"C:/Users/User/Desktop/mediumstress/anne index finger medium stress.xlsx\"\n",
    "        #all_data = all_data.append(df,ignore_index=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###here \"data--datafile\" is a DataFrame cannot be accessed through slicing,we should use iloc or .values functions \n",
    "\n",
    "        data=np.array([data.iloc[:,0].values])\n",
    "        print(data.shape)\n",
    "\n",
    "\n",
    "        for i in range(1,data.shape[1],10*fs):\n",
    "            \n",
    "            if(data[0,i:i+10*fs].dtype == 'int64'):\n",
    "                if(len(data[0,i:i+10*fs])== 1000):\n",
    "                    test_x=np.concatenate((test_x,data[0,i:i+10*fs].reshape((1,1000))))\n",
    "\n",
    "                    test_y=np.concatenate((test_y,[labels[label]]))\n",
    "            else:\n",
    "                print(f)\n",
    "    \n",
    "    print(test_x.shape)\n",
    "\n",
    "            \n",
    "       \n",
    "   \n",
    "          \n",
    "\n",
    "       \n",
    "   \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364, 1000)\n",
      "(1364,)\n",
      "(286, 1000)\n",
      "(286,)\n",
      "450\n",
      "376\n",
      "538\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1e9364f5e400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_y\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Medium'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_y\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Mild'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mt_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "print(t_x.shape)\n",
    "print(t_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "##trainCNN_x=np.array([x[0:961].reshape((31,31,1)) for x in t_x])\n",
    "##print(trainCNN_x.shape)\n",
    "##testCNN_x=np.array([x[0:961].reshape((31,31,1)) for x in test_x])\n",
    "##print(testCNN_x.shape)\n",
    "print(np.count_nonzero(t_y=='High'))\n",
    "print(np.count_nonzero(t_y=='Medium'))\n",
    "print(np.count_nonzero(t_y=='Mild'))\n",
    "t_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(t_x,t_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33916083916083917\n"
     ]
    }
   ],
   "source": [
    "test_score=lin_clf.score(test_x,test_y)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>611.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>...</td>\n",
       "      <td>364.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>...</td>\n",
       "      <td>311.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>316.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9    ...   \\\n",
       "0  703.0  701.0  705.0  704.0  703.0  703.0  703.0  703.0  703.0  449.0  ...    \n",
       "1  611.0  625.0  629.0  627.0  618.0  606.0  589.0  571.0  552.0  534.0  ...    \n",
       "2  341.0  338.0  336.0  335.0  333.0  332.0  332.0  331.0  331.0  332.0  ...    \n",
       "3  324.0  322.0  321.0  321.0  320.0  318.0  317.0  318.0  319.0  317.0  ...    \n",
       "4  313.0  313.0  314.0  317.0  316.0  318.0  318.0  318.0  317.0  318.0  ...    \n",
       "\n",
       "     991    992    993    994    995    996    997    998    999   0    \n",
       "0  352.0  365.0  386.0  414.0  448.0  487.0  525.0  559.0  589.0  High  \n",
       "1  364.0  361.0  362.0  361.0  359.0  355.0  352.0  347.0  344.0  High  \n",
       "2  321.0  321.0  321.0  321.0  321.0  321.0  320.0  323.0  322.0  High  \n",
       "3  311.0  312.0  313.0  314.0  315.0  316.0  316.0  315.0  314.0  High  \n",
       "4  316.0  314.0  314.0  312.0  311.0  313.0  312.0  309.0  313.0  High  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trainx_data = pd.DataFrame(t_x)\n",
    "trainy_data = pd.DataFrame(t_y)\n",
    "stress_data=pd.concat([trainx_data,trainy_data],axis=1)\n",
    "stress_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'High' 'High' ... 'Mild' 'Mild' 'Mild']\n"
     ]
    }
   ],
   "source": [
    "## one hot encoding is done by using scikit-learn class label encoder(),converts string output in to integer or binary output\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "print(t_y)\n",
    "encoder.fit(t_y)\n",
    "encoded_train_label = encoder.transform(t_y)\n",
    "# convert vector of integer to one hot encoding using keras function to_categorial() and craete dummy columm \n",
    "dummy_y = np_utils.to_categorical(encoded_train_label)\n",
    "#print(encoded_train_label)\n",
    "train_x,test_x,train_y,test_y = tts(t_x,t_y,test_size=0.2)\n",
    "# train_x=train_x.astype(int)\n",
    "# test_x=test_x.astype(int)\n",
    "# train_y=train_y.astype(int)\n",
    "# test_y=test_y.astype(int)\n",
    "\n",
    "\n",
    "#print(encoded_train_label)\n",
    "#print(dummy_y)\n",
    "##print(train_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(train_x)\n",
    "\n",
    "# Scale the train set\n",
    "train_x= scaler.transform(train_x)\n",
    "\n",
    "# Scale the test set\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/894 [===>..........................] - ETA: 34s - loss: 1.1330 - acc: 0.4000"
     ]
    }
   ],
   "source": [
    "### here neural network model is defined using relu as actviation function and 1 hidden layer with  8 neurons\n",
    "\n",
    "def neural_network():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(900, activation='relu'))\n",
    "    model.add(Dense(800,  activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(400,  activation='relu'))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "### now we us kerasclassifier as constructor from keras \n",
    "estimator = KerasClassifier(build_fn=neural_network, epochs=20, batch_size=5, verbose=1)\n",
    "## here we use 10-kfold cross_validation \n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(estimator, train_x, train_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fb66a56cfcb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-25121a4b3b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;36m3106.5008973291074\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred=rf.predict(X_valid)\n",
    "score = np.sqrt(mean_squared_error(y_valid,pred))\n",
    "print (score)\n",
    "3106.5008973291074\n",
    "# Evaluation while fitting the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
