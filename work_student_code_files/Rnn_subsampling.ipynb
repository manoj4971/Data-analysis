{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### computational python libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read training datasets\n",
    "buffer=pd.DataFrame()\n",
    "for i in range(1,2):\n",
    "    \n",
    "    subject_01 = pd.read_csv('Datasets_max/P_{0}_win_1000.csv'.format(i))\n",
    "    \n",
    "    buffer=pd.concat([buffer,subject_01],axis=0)\n",
    "### here we read validiation set of subject_20\n",
    "    subject_8 = pd.read_csv('Datasets_max/P_5_win_1000.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58284, 1001)\n",
      "(58284, 1001)\n"
     ]
    }
   ],
   "source": [
    "len(subject_01)\n",
    "print(subject_01.shape)\n",
    "print(buffer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58284, 1000)\n"
     ]
    }
   ],
   "source": [
    "#def getdata(X):\n",
    "    ### drop the label columm to assign data for testingset(train_x) set    \n",
    "    train_x = buffer.drop('Label',axis=1)\n",
    "    print(train_x.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58284, 1000)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "   \n",
    "    df=train_x\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    train_x = np.asarray(result)\n",
    "print(train_x.shape)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],1)\n",
    "\n",
    "    #### here we convert labelled_row data(eg:high_stress,medium_stress,mild_stress) in to int or float using label encoder function\n",
    "   \n",
    "    train_yy = X['Label']\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    ### encoded for train_y data set \n",
    "    encoder.fit(train_yy)\n",
    "    encoded_train_ylabel = encoder.transform(train_yy)\n",
    "    train_y = np_utils.to_categorical(encoded_train_ylabel)\n",
    "    return(train_x,train_y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58284, 1000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### train data set for model\n",
    "train_x,train_y = getdata(X=buffer)\n",
    "### test data set  for model\n",
    "\n",
    "\n",
    "test_x,test_y = getdata(X=subject_8)\n",
    "\n",
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def LSTM_RNN_vx(train_xx,train_yy,test_xx,test_yy,units,epoch,batch_size,inputshape,lr):\n",
    "    #Modeling RNN-LSTM\n",
    "        model=tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM (units,activation = 'tanh',input_shape =inputshape, return_sequences = True))\n",
    "        model.add(tf.keras.layers.LSTM (units,activation = 'tanh',input_shape =inputshape, return_sequences = False))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "   \n",
    "        model.add(tf.keras.layers.Dense(3,activation='sigmoid'))\n",
    "        #adagrad=keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "       \n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = \"rmsprop\" ,metrics=['acc'])\n",
    "        hist=model.fit(train_xx,train_yy,epochs=epoch,batch_size=batch_size,shuffle=True,validation_data=(test_xx,test_yy))\n",
    "        Y_pred=model.predict(test_xx)\n",
    "        return hist,Y_pred,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 254420 samples, validate on 59026 samples\n",
      "WARNING:tensorflow:From C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "254420/254420 [==============================] - 644s 3ms/sample - loss: 1.0233 - acc: 0.4804 - val_loss: 1.3102 - val_acc: 0.2955\n",
      "Epoch 2/10\n",
      "254420/254420 [==============================] - 725s 3ms/sample - loss: 1.0035 - acc: 0.5081 - val_loss: 1.3803 - val_acc: 0.2826\n",
      "Epoch 3/10\n",
      "254420/254420 [==============================] - 687s 3ms/sample - loss: 0.9972 - acc: 0.5121 - val_loss: 1.3228 - val_acc: 0.2851\n",
      "Epoch 4/10\n",
      "254420/254420 [==============================] - 828s 3ms/sample - loss: 0.9745 - acc: 0.5385 - val_loss: 1.4422 - val_acc: 0.3016\n",
      "Epoch 5/10\n",
      "254420/254420 [==============================] - 881s 3ms/sample - loss: 1.0120 - acc: 0.5210 - val_loss: 1.3966 - val_acc: 0.2988\n",
      "Epoch 6/10\n",
      "254420/254420 [==============================] - 750s 3ms/sample - loss: 0.9479 - acc: 0.5599 - val_loss: 1.4377 - val_acc: 0.2856\n",
      "Epoch 7/10\n",
      "254420/254420 [==============================] - 651s 3ms/sample - loss: 0.9467 - acc: 0.5563 - val_loss: 1.3633 - val_acc: 0.2773\n",
      "Epoch 8/10\n",
      "254420/254420 [==============================] - 680s 3ms/sample - loss: 0.9792 - acc: 0.5408 - val_loss: 1.4257 - val_acc: 0.2932\n",
      "Epoch 9/10\n",
      "254420/254420 [==============================] - 755s 3ms/sample - loss: 0.9392 - acc: 0.5573 - val_loss: 1.5359 - val_acc: 0.2469\n",
      "Epoch 10/10\n",
      "254420/254420 [==============================] - 1051s 4ms/sample - loss: 0.9505 - acc: 0.5502 - val_loss: 1.4425 - val_acc: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-10f4d57adc47>\", line 1, in <module>\n",
      "    hist,Y_pred,model = LSTM_RNN_vx(train_xx= train_x ,train_yy=train_y,test_xx=test_x,test_yy=test_y,units=10,epoch=10,batch_size=1000,inputshape=(1000,1),lr=0.1)\n",
      "  File \"<ipython-input-7-ade0df18b4d9>\", line 17, in LSTM_RNN_vx\n",
      "    Y_pred=model.predict(test_xx)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1113, in predict\n",
      "    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 329, in model_iteration\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3076, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\manoj\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "hist,Y_pred,model = LSTM_RNN_vx(train_xx= train_x ,train_yy=train_y,test_xx=test_x,test_yy=test_y,units=10,epoch=10,batch_size=1000,inputshape=(1000,1),lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved/subsampling_model1/intial3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1888cb6fd752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m### loss error plot for train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "### loss error plot for train set  \n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'],color = 'g')\n",
    "plt.legend\n",
    "plt.title('Train loss')\n",
    "plt.xlabel('standard output')\n",
    "plt.ylabel('predicted output')\n",
    "plt.show()\n",
    "fig.savefig('plots/model_11_train_loss.png',format='png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  accuray plot for training set\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['acc'],color = 'red')\n",
    "plt.legend\n",
    "plt.title('Train accuary')\n",
    "plt.xlabel('standard output')\n",
    "plt.ylabel('predicted output')\n",
    "plt.show()\n",
    "fig.savefig('plots/sub_samplingmodel_1_train_acc.png',format='png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss error for test set or (vadiation set)\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['val_loss'],color = 'g')\n",
    "plt.legend\n",
    "plt.title('valdiation loss')\n",
    "plt.xlabel('standard output')\n",
    "plt.ylabel('predicted output')\n",
    "plt.show()\n",
    "fig.savefig('plots/sub_samplingmodel_1_val_loss.png',format='png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### accuray plot for vadiation set\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['val_acc'],color = 'red')\n",
    "plt.legend\n",
    "plt.title('valdiation accuary')\n",
    "plt.xlabel('standard output')\n",
    "plt.ylabel('predicted output')\n",
    "plt.show()\n",
    "fig.savefig('plots/sub_samplingmodel_1_val_acc.png',format='png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
